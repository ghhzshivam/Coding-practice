{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Transfer Learning Implementation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimated time needed:  30 minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will learn to implement transfer learning using a pre-trained model in Keras.\n",
    "\n",
    "#### Learning objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "\n",
    " - Import necessary libraries and load the dataset.\n",
    " - Load a pre-trained model, VGG16, excluding the top layers.\n",
    " - Add new layers on top of the base model and compile the model.\n",
    " - Train the model on the new dataset.\n",
    " - Unfreeze some of the layers of the pre-trained model and fine-tune them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Guide: \n",
    "\n",
    "#### Step 1: Setup the Environment \n",
    "\n",
    "Before we start, make sure to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.16.2 matplotlib==3.9.1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation:\n",
    "- `tensorflow` is the main library for machine learning in Python.\n",
    "- `Sequential` is used to create a model with a linear stack of layers.\n",
    "- `Dense` and `Flatten` are types of layers that we will use in our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Load Pre-trained Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG16 model pre-trained on ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create and Compile the Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model and add the base model and new layers\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Change to the number of classes you have\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Placeholder Images**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('sample_data/class_a', exist_ok=True)\n",
    "os.makedirs('sample_data/class_b', exist_ok=True)\n",
    "\n",
    "# Create 10 sample images for each class\n",
    "for i in range(10):\n",
    "    # Create a blank white image for class_a\n",
    "    img = Image.fromarray(np.ones((224, 224, 3), dtype=np.uint8) * 255)\n",
    "    img.save(f'sample_data/class_a/img_{i}.jpg')\n",
    "\n",
    "    # Create a blank black image for class_b\n",
    "    img = Image.fromarray(np.zeros((224, 224, 3), dtype=np.uint8))\n",
    "    img.save(f'sample_data/class_b/img_{i}.jpg')\n",
    "\n",
    "print(\"Sample images created in 'sample_data/'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Train the Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'sample_data',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Verify if the generator has loaded images correctly\n",
    "print(f\"Found {train_generator.samples} images belonging to {train_generator.num_classes} classes.\")\n",
    "\n",
    "# Train the model\n",
    "if train_generator.samples > 0:\n",
    "    model.fit(train_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Fine-Tune the Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the top layers of the base model \n",
    "\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True \n",
    "\n",
    "# Compile the model again \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "# Train the model again \n",
    "model.fit(train_generator, epochs=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Visualize Training and Validation Loss\n",
    "\n",
    "**Objective:** Plot the training and validation loss to observe the learning process of the model.\n",
    "\n",
    "**Instructions:**\n",
    "1. Modify the training code to include validation data.\n",
    "2. Plot the training and validation loss for each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here for solution</summary> </br>\n",
    "\n",
    "```python\n",
    "# Modify data generator to include validation data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'sample_data',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'sample_data',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Train the model with validation data\n",
    "history = model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Experiment with Different Optimizers\n",
    "\n",
    "**Objective:** Experiment with different optimizers and observe their impact on model performance.\n",
    "\n",
    "**Instructions:**\n",
    "1. Change the optimizer from `adam` to `sgd` and `rmsprop`.\n",
    "2. Retrain the model with each optimizer and compare the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here for solution</summary> </br>\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import clone_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to reset the model weights\n",
    "def reset_model(model):\n",
    "    # Clone the model to reset weights\n",
    "    model_clone = clone_model(model)\n",
    "    model_clone.set_weights(model.get_weights())\n",
    "    return model_clone\n",
    "\n",
    "# Prepare to reset the model for each optimizer test\n",
    "initial_model = reset_model(model)  # Assume 'model' is the initial compiled model\n",
    "\n",
    "# Experiment with SGD optimizer\n",
    "sgd_model = reset_model(initial_model)  # Reset model\n",
    "sgd_model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_sgd = sgd_model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "# Plot training and validation accuracy for SGD\n",
    "plt.plot(history_sgd.history['accuracy'], label='Training Accuracy SGD')\n",
    "plt.plot(history_sgd.history['val_accuracy'], label='Validation Accuracy SGD')\n",
    "plt.title('Training and Validation Accuracy with SGD')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Experiment with RMSprop optimizer\n",
    "rmsprop_model = reset_model(initial_model)  # Reset model\n",
    "rmsprop_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_rmsprop = rmsprop_model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "# Plot training and validation accuracy for RMSprop\n",
    "plt.plot(history_rmsprop.history['accuracy'], label='Training Accuracy RMSprop')\n",
    "plt.plot(history_rmsprop.history['val_accuracy'], label='Validation Accuracy RMSprop')\n",
    "plt.title('Training and Validation Accuracy with RMSprop')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Evaluate the Model on a Test Set\n",
    "\n",
    "**Objective:** Evaluate the fine-tuned model on an unseen test set to assess its generalization performance.\n",
    "\n",
    "**Instructions:**\n",
    "1. Load a separate test set.\n",
    "2. Evaluate the model on this test set and report the accuracy and loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here for solution</summary> </br>\n",
    "\n",
    "```python\n",
    "# Load and preprocess the test dataset\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'sample_data',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Evaluate the fine-tuned model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "By completing these exercises, students will:\n",
    "\n",
    "1. Visualize the training and validation loss to gain insights into the training process.\n",
    "2. Experiment with different optimizers to understand their impact on model performance.\n",
    "3. Evaluate the fine-tuned model on an unseen test set to assess its generalization capability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Congratulations! In this lab, you have successfully implemented transfer learning using a pre-trained model in Keras. This lab exercise demonstrated how to train and fine-tune the model by unfreezing some of the layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "46890cfd422ab815a33a7c99b85ad21a549fbfa26e2bfd3ec07a5686815da9bc"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
